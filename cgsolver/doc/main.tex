\documentclass[letterpaper, 11pt]{article}
\usepackage[numbers]{natbib}
\usepackage{thm-restate}
\input{header.tex}
\newcommand*{\newton}{d}
\newcommand*{\hatnewton}{d_{N, T}}

\newcommand{\qup}{q}

\title{Solving convex relaxations for shortest paths in graphs of convex sets}
%\author{Frank Permenter}
\begin{document}
\maketitle
\abstract{ }

\section{Introduction}


\begin{defn}
  For a closed, convex function $f : \mathbb{R}^n \rightarrow \mathbb{R}$ 
  and point $\bar x \in \mathbb{R}$, let  $\tilde f : \mathbb{R}^n \times \mathbb{R}_{+} \rightarrow \mathbb{R} \cup \{\infty\}$
   denote the \emph{perspective} of $f$, defined as
  \begin{align}
\tilde f(x, \varphi) :=  \begin{cases}
  \varphi f(x/\varphi) & \textit{if } \varphi > 0 \\
  \lim_{\varphi \rightarrow 0} \varphi f(\bar x + x/\varphi) & \textit{if } \varphi = 0 \\
  \end{cases}
  \end{align}
  where the limit can be shown to be independent of $\bar x$.
\end{defn}

\begin{defn}
Denote by $\tilde X \subseteq \mathbb{R}^{n} \times \mathbb{R}_{+}$
the \emph{perspective} of $X \subseteq \mathbb{R}^n$, defined as
\[
  \tilde X := \{ (x, \varphi) :   x \in  \varphi X \}.
\]
\end{defn}

\begin{defn}
  Denote by $\epi(f)$ the \emph{epigraph} of $f : \mathbb{R}^n \rightarrow \mathbb{R}$, defined as
\[
  \epi(f) := \{ (x, t) \in \dom(f) \times \mathbb{R} : f(x) \le t \}
\]
\end{defn}


\begin{lem}
  For any closed, convex function $f$, the epigraph $\epi(\tilde f)$
  of the perspective function $\tilde f$ is a convex cone.
  \begin{proof}
    Since $\epi(\tilde f)$ is a convex set we only need to show it is a cone.
    Towards this, suppose $\varphi f(x/\varphi) \le t$. Multiplying both sides by $\alpha > 0$
    shows that $\alpha \varphi f(x/\varphi) \le  \alpha t$.
    Hence, $\alpha \varphi f(\alpha x/\alpha \varphi) \le  \alpha t$,
    showing that $(\alpha x, \alpha \varphi, \alpha t) \in \epi(\tilde f)$
    as desired.
  \end{proof}
\end{lem}

%Up to permutation of the parameters $t$ and $\lambda$,
%the epigraph of the perspective function is the perspective set of the epigraph.
%\begin{lem}
%  Let $X = \epi(f)$ and suppose that $\tilde f(0, 0) = 0$ when $\lambda = 0$.  Then $( (x, t), \lambda ) \in \tilde X$ if and only
%  if $( (x, \lambda), t ) \in \epi(\tilde f)$.
%  \begin{proof}
%    Suppose $\lambda > 0$. Then,
%      $\lambda  f( \frac{1}{\lambda} x) \le t$ if and only if $f( \frac{1}{\lambda} x) \le \frac{t}{\lambda}$.
%      In other words,
%      $ ((x, \lambda) ,t) \in \epi \tilde f$ if and only if
%      $\frac{1}{\lambda}(x, t) \in \epi(f)$.
%      Further,  $\frac{1}{\lambda}(x, t) \in \epi(f)$ if and only if $( (x, t),  \lambda) \in \tilde X$,
%      proving the claim for $\lambda > 0$.
%
%    Consider $\lambda =0$. Then $((x,t), \lambda) \in \tilde X$ implies 
%    that $(x, t) = 0$.   By assumption $\tilde f(x, \lambda) = 0$ when
%    $x =0$ and $\lambda = 0$. Hence, $((x, \lambda), t) \in \epi \tilde f$.
%  \end{proof}
%\end{lem}


\section{Shortest paths in graphs of convex sets}
Given a directed graph $G(V, E)$ the \emph{shortest path} between $s, t \in V$
is a collection of edges $\pi \subseteq E$ connecting $s$ and $t$ that have minimum cumulative weight.
In the classical statement of this problem, the weight
of each edge is a constant function, independent of the path $\pi$. 
A recent generalization considers a richer class of weight functions,
defined by associating each vertex $v \in V$ with a convex set $X_v \subseteq \mathbb{R}^n$ 
and each  edge $e \in E$ with a convex function 
$l_e : \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$.
To assign weights, one first selects a set of points $\{x_v \in X_v\}_{v \in V}$
and next evaluates $l_e(x_{u}, x_{v})$ for each edge $e = (u, v) \in E$.  The
shortest-path problem seeks a path $\pi$ and point-set $\{x_v \in X_v\}_{v \in
V}$ that minimize the cumulative sum of edge-weights.  An optimal path is
called the shortest path in the \emph{graph-of-convex-sets} defined by
$\{X_v\}_{v\in V}$ and $G$.

As shown in~\cite{}, shortest paths in graphs-of-convex-sets  can be found
using mixed-integer convex optimization.  The specific formulation uses
\emph{flow variables} $\varphi_e \in \mathbb{R}$ and a pair of spatial
variables $(y_e, z_e) \in \mathbb{R}^n \times \mathbb{R}^n$ for each edge.  It
minimizes the perspective $\tilde l_e(y, z, \varphi)$ of the edge-cost $l_e$
subject to spatial, flow, and degree constraints.  These constraints in turn
are defined by the set of incoming and outgoing edges for each vertex $v \in
V$, denoted $E^{in}_v \subseteq E$ and $E^{out}_v \subseteq E$, respectively.
Letting $s, t \in \mathcal{V}$ denote the desired end-points of the path and
$\delta_{uv}$ the Kronecker delta, the formulation is stated as follows:
\begin{subequations}\label{eq:shortest_path}
  \begin{align}
  \minimize_{y_e, z_e, \varphi_e, s_v} &\sum_{e\in E}\tilde l_e(y_e, z_e, \varphi_e) \nonumber \\
  \mbox{subject to }  
  & (y_e, \varphi_e) \in \tilde{ X_u},    (z_e, \varphi_e) \in \tilde{ X_v}  &\forall  e=(u, v) \in E \label{eq:spatialConstraint}\\
  & \sum_{e \in E^{in}_v} \varphi_e + \delta_{sv} = \sum_{e \in E^{out}_v} \varphi_e + \delta_{tv} \le 1 &\forall v \in V  \label{eq:conservationFlow}\\
  & \sum_{e \in E^{out}_v} y_e = \sum_{e \in E^{in}_v} z_e &\forall v \in V - \{s, t\}   \label{eq:spatialConservationFlow}\\ 
  & \varphi_e \in \{0, 1\}  & \forall  e \in E  \label{eq:booleanConstraints}
  \end{align}
\end{subequations}
Here,~\eqref{eq:conservationFlow}  imposes both \emph{conservation of flow} and
maximum flow constraints for each node. Combined with~\eqref{eq:booleanConstraints},
it requires that the subset of edges $e$ with $\varphi_e = 1$ form a simple path from $s$ to $t$.
The constraint~\eqref{eq:spatialConservationFlow}
is called \emph{spatial conservation of flow} and, for each node, imposes consistency between
the points associated with incident  edges. Finally,~\eqref{eq:spatialConstraint} combined with~\eqref{eq:booleanConstraints}
says that either $(y_e, z_e) \in X_u \times X_v$  or $(y_e, z_e) = 0$.

\subsection{Convex relaxations}
Our goal is to efficiently solve the convex relaxation of~\eqref{eq:shortest_path}
that arises by replacing the boolean constraints $\varphi_e \in \{0, 1\}$ 
with linear inequalities $0 \le \varphi_e \le 1$. Towards this, we
state the relaxation in a form that is amenable to interior-point methods and sparsity 
analysis.   To begin, associate with each vertex $v$  an inner-product space $\mathcal{V}_v$,
a linear map $A_v : \mathbb{R}^{d} \rightarrow \mathcal{V}_e$, a
convex cone $\coneName_v \subseteq \mathcal{V}_v$ and a vector $b_v \in \mathcal{V}_v$ satisfying
\[
  \tilde X_v = \left\{ (y, \varphi) \in \mathbb{R}^{d+1} : A_v y  + b_v \varphi \in \coneName_v  \right\} \qquad
\]
In this notation, the relaxation takes the form
\begin{align}~\label{cp:coneRelax}
  \begin{aligned}
    \minimize_{y_e, z_e, \varphi_e, s_e} & \sum_{e \in E}\tilde l_e(y_e, z_e, \varphi_e)\\
    \mbox{subject to } &A_u y_e + b_u \varphi_e \in \coneName_u ,  A_v z_e + b_v \varphi_e \in \coneName_v  & \forall e = (u, v) \in E \\
                      & 1 \ge \varphi \ge 0,  \\
                      & F^{in} \varphi  + s   = f_1, s \ge 0\\
                      & (F^{in} - F^{out}) \varphi  = f_2\\
                      & (F^{in} \otimes I_n)  y - (F^{out} \otimes I_n) z  = 0\\
  \end{aligned}
\end{align}
where $y \in \mathbb{R}^{ n |E|} $ and $z \in \mathbb{R}^{ n |E|}$ denote the concatenation of the $y_e$ and $z_e$
into vectors, and $s \in \mathbb{R}^{|V|}$ is a slack variable for the degree constraint. 
The matrices $F^{in} \in \mathbb{R}^{|V| \times |E|}$ 
and $F^{out} \in \mathbb{R}^{|V| \times |E|}$ are the incidence matrices for incoming and outgoing edges respectively.
Precisely, $[F^{in}]_{ve} = 1$ if edge $e \in E^{in}_{v}$ and is otherwise zero;
similarly, $[F^{out}]_{ve} = 1$ if edge $e \in E^{out}_{v}$ and is otherwise zero.
Finally, $I_n \in \mathbb{R}^{n \times n}$ denotes the identity matrix of order $n$,
and $f_1 \in \mathbb{R}^{|V|}$ and $f_2\in \mathbb{R}^{|V|}$ are constants set according to~\eqref{eq:conservationFlow}.

\subsection{Barrier methods}
The convex relaxation~\eqref{cp:coneRelax} is a special case of the standard-form cone-programming problem
\begin{align}~\label{cp:standardForm}
  \begin{aligned}
    \minimize \;\; &   f(x)\\
    \mbox{subject to } & Ax + b \in \coneName
                       & Fx = g
  \end{aligned}
\end{align}
The barrier method solves~\eqref{cp:standardForm} by
replacing the constraint $Ax + b \in \coneName$ with a penalty function  
$g_K : \inter \coneName \rightarrow \mathbb{R}$ and iteratively solving the optimality conditions of
\begin{align}~\label{qp:barrier}
  \begin{aligned}
    \minimize \;\; &   f(x) + \mu g_{\coneName}(Ax+b) \\
    \mbox{subject to } 
                       & Fx = g
  \end{aligned}
\end{align}
for a decreasing sequence of $\mu > 0$.  
Letting $f_{\mu} = f(x) + \mu  g_K(Ax+b)$, these conditions read
\begin{align}\label{eq:barrier}
  \nabla f_{\mu}(x)+ F^T \lambda = 0, Fx = g,
\end{align}
which in turn can solved using  Newton's method. That is, one can iteratively take
$x \leftarrow x + \Delta x$ where $\Delta x$ solves, for some $\lambda$, the following linear system 
\begin{align}~\label{eq:kktsystem}
  \begin{bmatrix}
    \nabla^2 f_\mu(x)  & F^T  \\
    F  & 0 
  \end{bmatrix}
  \begin{bmatrix}
    \Delta x\\
    \lambda
  \end{bmatrix}
=
  \begin{bmatrix}
    0\\
   g - Fx
  \end{bmatrix}.
\end{align}
We are interested in efficient solution of such systems
when~\eqref{cp:standardForm} is the convex relaxation~\eqref{cp:coneRelax}.  In
this case, we'll see that  $f_\mu(x)$ is always block diagonal and $F$ is
sparse when the graph $G$ has few edges. This in turn allows us to efficiently
invert the positive definite Schur complement matrix $F (\nabla^2 f_\mu(x))^{-1} F^T$
using the conjugate-gradient method.

\subsection{Sparsity of the Newton system}


Recall that the convex relaxation~\eqref{cp:coneRelax} consists of a set of
edge variables $(y_e , z_e, \varphi_e) \in \mathbb{R}^n \times \mathbb{R}^n \times
\mathbb{R}$ for each $e \in E$ and a vector $s \in \mathbb{R}^{|V|}$ for the
vertex degree constraints.  By letting $w \in \mathbb{R}^{(2n+1)|E|}$ denote
the concatenation of $(y_e, z_e, \varphi_e)_{e \in E}$, we can express the matrix
of the Newton system~\eqref{eq:kktsystem} as follows:
\begin{align}
  \begin{bmatrix}
    \nabla^2 f_\mu(x)  & F^T  \\
    F  & 0 
  \end{bmatrix} = 
  \bordermatrix{~& w & s & \lambda_1 & \lambda_2  \cr
  &  \diag(G_e)_{e \in E}  & 0  &  F_1^T & F_2^T  \cr
  &  0  & \diag(d_v)_{v \in V}   & I & 0\cr
  &  F_1  & I & 0  & 0 \cr
  &  F_2  & 0 & 0  & 0\cr
  },
\end{align}
where $x = (w, s)$ and $\lambda = (\lambda_1, \lambda_2)$.  Here,  $F_1$ and
$F_2$ are sparse matrices, constructed from the node-edge incidence matrices
$F^{in}$ and $F^{out}$.  The diagonal matrix $\diag(d_v)_{v \in V}$  consists
of barrier terms $d_v$ for the degree constraints at vertex $v$.  Finally, the
block-diagonal matrix $\diag(G_e)_{e \in E}$ consists of blocks $G_e \in
\mathbb{R}^{ (2d + 1) \times (2d+1)}$ encoding objective and barrier terms for
$(y_e, z_e, \varphi_e)_{e \in E}$. For each edge $e=(u,v)$, the block $G_e$ has
form:
\[
G_e =
\nabla^2 \tilde l_e(y_e, z_e, \varphi_e) +
  \bordermatrix{~& y_e & z_e & \varphi_e  \cr
&  A_u^T Q^e_u A_u  \cr
&    0          & A_v^T Q^e_v A_v \cr
&   b_u^T Q^e_u A_u    & b_v^T Q^e_v A_v      &  k_e  \cr
 }
\]
where   $Q^e_u$  and $Q^e_p$ arise from the Hessians of the barrier functions
used for spatial constraints, and $k_{e}$ is constructed from the barrier for
$1 \ge \varphi_e \ge 0$.  Finally, $\nabla^2 \tilde l_e$ denotes the Hessian of
the edge-cost function $\tilde l_e(y_e, z_e, \varphi_e)$, when it is twice
differentiable.



%\begin{align}
%  \bordermatrix{~& w  & \lambda_1 & \lambda_2  \cr
%  &  G  &   &   \cr
%  &  F_1 & -S^{-1}  & 0  & \cr
%  &  F_2 &0 & 0  & \cr
%  }
%\end{align}
\end{document}

\section{Epigraphs of the objective}

When $\epi \tilde l_e$ is a self-concordant function,
it suffices to take $H_{l}$ equal to its Hessian.
When self-concondance fails, standard practice selects $H_l$
by first describing the \emph{epigraph} of $l_e$ using
cone constraints. For instance, one selects $B_v : \mathbb{R}^{2d+1} \rightarrow \mathcal{V}_v$
satisfying
\[
  \epi \tilde l_e = \left\{ (y,  z, \varphi, t) : B_e(y, z, \varphi, t) \in \coneName_e\right \}
\]
Like the spatial constraints, we associate with $\epi \tilde l_e$
a positive definite matrix
\[
  H_e = B_e^T Q_{l_e} B_e,
\]
where $Q_{l_e}$ depends on $\coneName_{l_e}$
The matrix $H_l$ is the Schur complement of $H_e$ obtained by eliminating the epigraph
parameter $t$.




\end{document}

